{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question 1***\n",
      "Wrote 10000 lines.\n",
      "\n",
      "***Question 2***\n",
      "Step #99, avg. train loss: 296211.12500\n",
      "Step #199, avg. train loss: 42216.94141\n",
      "Step #299, avg. train loss: 23683.66992\n",
      "Step #400, epoch #1, avg. train loss: 17236.32812\n",
      "Step #500, epoch #1, avg. train loss: 12332.32617\n",
      "Step #600, epoch #1, avg. train loss: 10105.65723\n",
      "Step #700, epoch #2, avg. train loss: 8618.09961\n",
      "Step #800, epoch #2, avg. train loss: 7134.90625\n",
      "Step #900, epoch #2, avg. train loss: 5592.15674\n",
      "Step #1000, epoch #3, avg. train loss: 5675.46143\n",
      "Step #1100, epoch #3, avg. train loss: 4687.73047\n",
      "Step #1200, epoch #3, avg. train loss: 3635.77002\n",
      "Step #1300, epoch #4, avg. train loss: 3317.61719\n",
      "Step #1400, epoch #4, avg. train loss: 3177.59448\n",
      "Step #1500, epoch #4, avg. train loss: 2577.63745\n",
      "Step #1600, epoch #5, avg. train loss: 2427.60620\n",
      "Step #1700, epoch #5, avg. train loss: 2418.82910\n",
      "Step #1800, epoch #5, avg. train loss: 1904.46033\n",
      "Step #1900, epoch #6, avg. train loss: 1715.80701\n",
      "Step #2000, epoch #6, avg. train loss: 1555.14331\n",
      "Step #2100, epoch #6, avg. train loss: 1501.01111\n",
      "Step #2200, epoch #7, avg. train loss: 1445.28137\n",
      "Step #2300, epoch #7, avg. train loss: 1187.77942\n",
      "Step #2400, epoch #7, avg. train loss: 1053.35107\n",
      "Step #2500, epoch #7, avg. train loss: 1167.98132\n",
      "Step #2600, epoch #8, avg. train loss: 945.20868\n",
      "Step #2700, epoch #8, avg. train loss: 869.21368\n",
      "Step #2800, epoch #8, avg. train loss: 921.17474\n",
      "Step #2900, epoch #9, avg. train loss: 791.04462\n",
      "Step #3000, epoch #9, avg. train loss: 743.96326\n",
      "Step #3100, epoch #9, avg. train loss: 726.76398\n",
      "Step #3200, epoch #10, avg. train loss: 712.43994\n",
      "Step #3300, epoch #10, avg. train loss: 670.31177\n",
      "Step #3400, epoch #10, avg. train loss: 635.33514\n",
      "Step #3500, epoch #11, avg. train loss: 684.99396\n",
      "Step #3600, epoch #11, avg. train loss: 600.52002\n",
      "Step #3700, epoch #11, avg. train loss: 605.60632\n",
      "Step #3800, epoch #12, avg. train loss: 655.96216\n",
      "Step #3900, epoch #12, avg. train loss: 579.44928\n",
      "Step #4000, epoch #12, avg. train loss: 577.66772\n",
      "Step #4100, epoch #13, avg. train loss: 642.89349\n",
      "Step #4200, epoch #13, avg. train loss: 639.13788\n",
      "Step #4300, epoch #13, avg. train loss: 627.52863\n",
      "Step #4400, epoch #14, avg. train loss: 599.60333\n",
      "Step #4500, epoch #14, avg. train loss: 603.30493\n",
      "Step #4600, epoch #14, avg. train loss: 714.73322\n",
      "Step #4700, epoch #15, avg. train loss: 775.33240\n",
      "Step #4800, epoch #15, avg. train loss: 678.26416\n",
      "Step #4900, epoch #15, avg. train loss: 735.46448\n",
      "Step #5000, epoch #15, avg. train loss: 742.51819\n",
      "Step #5100, epoch #16, avg. train loss: 700.79626\n",
      "Step #5200, epoch #16, avg. train loss: 795.27032\n",
      "Step #5300, epoch #16, avg. train loss: 764.21429\n",
      "Step #5400, epoch #17, avg. train loss: 769.69995\n",
      "Step #5500, epoch #17, avg. train loss: 718.43909\n",
      "Step #5600, epoch #17, avg. train loss: 725.87030\n",
      "Step #5700, epoch #18, avg. train loss: 624.51672\n",
      "Step #5800, epoch #18, avg. train loss: 612.13733\n",
      "Step #5900, epoch #18, avg. train loss: 588.53943\n",
      "Step #6000, epoch #19, avg. train loss: 505.46860\n",
      "Step #6100, epoch #19, avg. train loss: 551.35193\n",
      "Step #6200, epoch #19, avg. train loss: 488.69220\n",
      "Step #6300, epoch #20, avg. train loss: 481.57648\n",
      "Step #6400, epoch #20, avg. train loss: 441.90808\n",
      "Step #6500, epoch #20, avg. train loss: 416.92825\n",
      "Step #6600, epoch #21, avg. train loss: 448.64294\n",
      "Step #6700, epoch #21, avg. train loss: 421.83423\n",
      "Step #6800, epoch #21, avg. train loss: 359.05551\n",
      "Step #6900, epoch #22, avg. train loss: 341.09747\n",
      "Step #7000, epoch #22, avg. train loss: 375.76352\n",
      "Step #7100, epoch #22, avg. train loss: 329.84775\n",
      "Step #7200, epoch #23, avg. train loss: 327.60403\n",
      "Step #7300, epoch #23, avg. train loss: 331.86060\n",
      "Step #7400, epoch #23, avg. train loss: 320.64844\n",
      "Step #7500, epoch #23, avg. train loss: 291.08240\n",
      "Step #7600, epoch #24, avg. train loss: 278.19678\n",
      "Step #7700, epoch #24, avg. train loss: 282.11176\n",
      "Step #7800, epoch #24, avg. train loss: 285.87585\n",
      "Step #7900, epoch #25, avg. train loss: 269.74371\n",
      "Step #8000, epoch #25, avg. train loss: 252.06918\n",
      "Step #8100, epoch #25, avg. train loss: 255.30206\n",
      "Step #8200, epoch #26, avg. train loss: 228.26003\n",
      "Step #8300, epoch #26, avg. train loss: 247.89914\n",
      "Step #8400, epoch #26, avg. train loss: 248.41142\n",
      "Step #8500, epoch #27, avg. train loss: 216.03836\n",
      "Step #8600, epoch #27, avg. train loss: 234.26860\n",
      "Step #8700, epoch #27, avg. train loss: 225.14961\n",
      "Step #8800, epoch #28, avg. train loss: 227.59868\n",
      "Step #8900, epoch #28, avg. train loss: 223.89183\n",
      "Step #9000, epoch #28, avg. train loss: 219.80588\n",
      "Step #9100, epoch #29, avg. train loss: 228.65355\n",
      "Step #9200, epoch #29, avg. train loss: 203.83301\n",
      "Step #9300, epoch #29, avg. train loss: 216.63429\n",
      "Step #9400, epoch #30, avg. train loss: 228.39761\n",
      "Step #9500, epoch #30, avg. train loss: 222.42941\n",
      "Step #9600, epoch #30, avg. train loss: 223.09021\n",
      "Step #9700, epoch #30, avg. train loss: 219.23209\n",
      "Step #9800, epoch #31, avg. train loss: 229.73090\n",
      "Step #9900, epoch #31, avg. train loss: 237.80377\n",
      "Step #10000, epoch #31, avg. train loss: 227.41492\n",
      "Out of sample (RMSE): 11.530587196192775\n",
      "\n",
      "***Question 3***\n",
      "length: (5.4895, 2.847402416247483)\n",
      "width: (5.4783, 2.85470559680056)\n",
      "height: (5.52, 2.8729819704516513)\n",
      "     height    length     width\n",
      "0 -0.877137 -1.576700 -1.218444\n",
      "1 -0.180997 -0.874306 -1.218444\n",
      "2 -0.877137 -0.523108 -1.568743\n",
      "\n",
      "***Question 4***\n",
      "Fold #1\n",
      "Step #50, epoch #12, avg. train loss: 0.07184, avg. val loss: 0.05284\n",
      "Step #100, epoch #25, avg. train loss: 0.01671, avg. val loss: 0.01638\n",
      "Step #150, epoch #37, avg. train loss: 0.01401, avg. val loss: 0.01679\n",
      "Step #200, epoch #50, avg. train loss: 0.01323, avg. val loss: 0.01677\n",
      "Step #250, epoch #62, avg. train loss: 0.01217, avg. val loss: 0.01708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best step:\n",
      " step 97 with loss 0.013468504883348942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 0.17531210760832266\n",
      "Fold #2\n",
      "Step #50, epoch #12, avg. train loss: 0.07019, avg. val loss: 0.04958\n",
      "Step #100, epoch #25, avg. train loss: 0.01796, avg. val loss: 0.01659\n",
      "Step #150, epoch #37, avg. train loss: 0.01597, avg. val loss: 0.01305\n",
      "Step #200, epoch #50, avg. train loss: 0.01384, avg. val loss: 0.01132\n",
      "Step #250, epoch #62, avg. train loss: 0.01356, avg. val loss: 0.01145\n",
      "Step #300, epoch #75, avg. train loss: 0.01263, avg. val loss: 0.01069\n",
      "Step #350, epoch #87, avg. train loss: 0.01236, avg. val loss: 0.01079\n",
      "Step #400, epoch #100, avg. train loss: 0.01195, avg. val loss: 0.01049\n",
      "Step #450, epoch #112, avg. train loss: 0.01246, avg. val loss: 0.01069\n",
      "Step #500, epoch #125, avg. train loss: 0.01185, avg. val loss: 0.01097\n",
      "Step #550, epoch #137, avg. train loss: 0.01109, avg. val loss: 0.01040\n",
      "Fold score (RMSE): 0.14272974831031332\n",
      "Fold #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best step:\n",
      " step 362 with loss 0.009098603390157223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #50, epoch #12, avg. train loss: 0.06759, avg. val loss: 0.06043\n",
      "Step #100, epoch #25, avg. train loss: 0.01754, avg. val loss: 0.02284\n",
      "Step #150, epoch #37, avg. train loss: 0.01408, avg. val loss: 0.01943\n",
      "Step #200, epoch #50, avg. train loss: 0.01232, avg. val loss: 0.01788\n",
      "Step #250, epoch #62, avg. train loss: 0.01224, avg. val loss: 0.01713\n",
      "Step #300, epoch #75, avg. train loss: 0.01184, avg. val loss: 0.01636\n",
      "Step #350, epoch #87, avg. train loss: 0.01112, avg. val loss: 0.01614\n",
      "Step #400, epoch #100, avg. train loss: 0.01094, avg. val loss: 0.01589\n",
      "Step #450, epoch #112, avg. train loss: 0.01137, avg. val loss: 0.01569\n",
      "Step #500, epoch #125, avg. train loss: 0.01110, avg. val loss: 0.01536\n",
      "Step #550, epoch #137, avg. train loss: 0.01038, avg. val loss: 0.01520\n",
      "Step #600, epoch #150, avg. train loss: 0.01020, avg. val loss: 0.01473\n",
      "Step #650, epoch #162, avg. train loss: 0.01022, avg. val loss: 0.01494\n",
      "Step #700, epoch #175, avg. train loss: 0.01001, avg. val loss: 0.01469\n",
      "Step #750, epoch #187, avg. train loss: 0.00978, avg. val loss: 0.01471\n",
      "Step #800, epoch #200, avg. train loss: 0.00964, avg. val loss: 0.01465\n",
      "Step #850, epoch #212, avg. train loss: 0.00929, avg. val loss: 0.01483\n",
      "Step #900, epoch #225, avg. train loss: 0.00927, avg. val loss: 0.01459\n",
      "Step #950, epoch #237, avg. train loss: 0.00891, avg. val loss: 0.01437\n",
      "Step #1000, epoch #250, avg. train loss: 0.00873, avg. val loss: 0.01450\n",
      "Step #1050, epoch #262, avg. train loss: 0.00870, avg. val loss: 0.01465\n",
      "Step #1100, epoch #275, avg. train loss: 0.00849, avg. val loss: 0.01454\n",
      "Step #1150, epoch #287, avg. train loss: 0.00856, avg. val loss: 0.01492\n",
      "Step #1200, epoch #300, avg. train loss: 0.00872, avg. val loss: 0.01474\n",
      "Step #1250, epoch #312, avg. train loss: 0.00820, avg. val loss: 0.01480\n",
      "Step #1300, epoch #325, avg. train loss: 0.00812, avg. val loss: 0.01476\n",
      "Fold score (RMSE): 0.161749386296102\n",
      "Fold #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best step:\n",
      " step 1106 with loss 0.011062948033213615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #50, epoch #12, avg. train loss: 0.06714, avg. val loss: 0.07087\n",
      "Step #100, epoch #25, avg. train loss: 0.01583, avg. val loss: 0.02708\n",
      "Step #150, epoch #37, avg. train loss: 0.01299, avg. val loss: 0.02386\n",
      "Step #200, epoch #50, avg. train loss: 0.01127, avg. val loss: 0.02296\n",
      "Step #250, epoch #62, avg. train loss: 0.01074, avg. val loss: 0.02246\n",
      "Step #300, epoch #75, avg. train loss: 0.01066, avg. val loss: 0.02217\n",
      "Step #350, epoch #87, avg. train loss: 0.01011, avg. val loss: 0.02159\n",
      "Step #400, epoch #100, avg. train loss: 0.01047, avg. val loss: 0.02184\n",
      "Step #450, epoch #112, avg. train loss: 0.01020, avg. val loss: 0.02160\n",
      "Step #500, epoch #125, avg. train loss: 0.00995, avg. val loss: 0.02182\n",
      "Step #550, epoch #137, avg. train loss: 0.00969, avg. val loss: 0.02158\n",
      "Step #600, epoch #150, avg. train loss: 0.00964, avg. val loss: 0.02152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best step:\n",
      " step 438 with loss 0.020158855244517326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 0.21273141903164636\n",
      "Fold #5\n",
      "Step #50, epoch #12, avg. train loss: 0.06887, avg. val loss: 0.05595\n",
      "Step #100, epoch #25, avg. train loss: 0.01576, avg. val loss: 0.02118\n",
      "Step #150, epoch #37, avg. train loss: 0.01299, avg. val loss: 0.01812\n",
      "Step #200, epoch #50, avg. train loss: 0.01231, avg. val loss: 0.01801\n",
      "Step #250, epoch #62, avg. train loss: 0.01176, avg. val loss: 0.01777\n",
      "Step #300, epoch #75, avg. train loss: 0.01124, avg. val loss: 0.01732\n",
      "Step #350, epoch #87, avg. train loss: 0.01088, avg. val loss: 0.01720\n",
      "Step #400, epoch #100, avg. train loss: 0.01070, avg. val loss: 0.01711\n",
      "Step #450, epoch #112, avg. train loss: 0.01051, avg. val loss: 0.01707\n",
      "Step #500, epoch #125, avg. train loss: 0.01010, avg. val loss: 0.01683\n",
      "Step #550, epoch #137, avg. train loss: 0.00982, avg. val loss: 0.01661\n",
      "Step #600, epoch #150, avg. train loss: 0.00970, avg. val loss: 0.01654\n",
      "Step #650, epoch #162, avg. train loss: 0.01009, avg. val loss: 0.01689\n",
      "Step #700, epoch #175, avg. train loss: 0.00969, avg. val loss: 0.01670\n",
      "Step #750, epoch #187, avg. train loss: 0.00910, avg. val loss: 0.01665\n",
      "Step #800, epoch #200, avg. train loss: 0.00967, avg. val loss: 0.01666\n",
      "Step #850, epoch #212, avg. train loss: 0.00903, avg. val loss: 0.01657\n",
      "Step #900, epoch #225, avg. train loss: 0.00893, avg. val loss: 0.01664\n",
      "Step #950, epoch #237, avg. train loss: 0.00902, avg. val loss: 0.01661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best step:\n",
      " step 786 with loss 0.011288278736174107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (RMSE): 0.18455804191270428\n",
      "Final, Out of Sample Score (RMSE): 0.17696627225086287\n",
      "\n",
      "***Question 5***\n",
      "Fold #1\n",
      "Step #50, epoch #5, avg. train loss: 1.51485, avg. val loss: 1.23125\n",
      "Step #100, epoch #10, avg. train loss: 0.69187, avg. val loss: 0.53933\n",
      "Step #150, epoch #15, avg. train loss: 0.44803, avg. val loss: 0.30869\n",
      "Step #200, epoch #20, avg. train loss: 0.32595, avg. val loss: 0.22045\n",
      "Step #250, epoch #25, avg. train loss: 0.28483, avg. val loss: 0.19665\n",
      "Step #300, epoch #30, avg. train loss: 0.26852, avg. val loss: 0.17732\n",
      "Step #350, epoch #35, avg. train loss: 0.24599, avg. val loss: 0.15890\n",
      "Step #400, epoch #40, avg. train loss: 0.23328, avg. val loss: 0.15374\n",
      "Step #450, epoch #45, avg. train loss: 0.21888, avg. val loss: 0.14830\n",
      "Step #500, epoch #50, avg. train loss: 0.21994, avg. val loss: 0.15145\n",
      "Fold score: 0.9810708435174292\n",
      "Fold #2\n",
      "Step #50, epoch #5, avg. train loss: 1.50325, avg. val loss: 1.35368\n",
      "Step #100, epoch #10, avg. train loss: 0.68610, avg. val loss: 0.79987\n",
      "Step #150, epoch #15, avg. train loss: 0.44881, avg. val loss: 0.60935\n",
      "Step #200, epoch #20, avg. train loss: 0.33735, avg. val loss: 0.46706\n",
      "Step #250, epoch #25, avg. train loss: 0.27719, avg. val loss: 0.38541\n",
      "Step #300, epoch #30, avg. train loss: 0.24578, avg. val loss: 0.33329\n",
      "Step #350, epoch #35, avg. train loss: 0.23143, avg. val loss: 0.30299\n",
      "Step #400, epoch #40, avg. train loss: 0.20649, avg. val loss: 0.27676\n",
      "Step #450, epoch #45, avg. train loss: 0.18573, avg. val loss: 0.25823\n",
      "Step #500, epoch #50, avg. train loss: 0.19556, avg. val loss: 0.26374\n",
      "Fold score: 0.9746794344808963\n",
      "Fold #3\n",
      "Step #50, epoch #5, avg. train loss: 1.48688, avg. val loss: 1.32485\n",
      "Step #100, epoch #10, avg. train loss: 0.77892, avg. val loss: 0.81879\n",
      "Step #150, epoch #15, avg. train loss: 0.60576, avg. val loss: 0.66166\n",
      "Step #200, epoch #20, avg. train loss: 0.52940, avg. val loss: 0.59634\n",
      "Step #250, epoch #25, avg. train loss: 0.48060, avg. val loss: 0.55534\n",
      "Step #300, epoch #30, avg. train loss: 0.44777, avg. val loss: 0.51979\n",
      "Step #350, epoch #35, avg. train loss: 0.42587, avg. val loss: 0.49135\n",
      "Step #400, epoch #40, avg. train loss: 0.40386, avg. val loss: 0.46887\n",
      "Step #450, epoch #45, avg. train loss: 0.38771, avg. val loss: 0.44600\n",
      "Step #500, epoch #50, avg. train loss: 0.37028, avg. val loss: 0.42531\n",
      "Fold score: 0.9746794344808963\n",
      "Fold #4\n",
      "Step #50, epoch #5, avg. train loss: 1.45293, avg. val loss: 1.35825\n",
      "Step #100, epoch #10, avg. train loss: 0.74098, avg. val loss: 0.72190\n",
      "Step #150, epoch #15, avg. train loss: 0.48421, avg. val loss: 0.49895\n",
      "Step #200, epoch #20, avg. train loss: 0.37166, avg. val loss: 0.42331\n",
      "Step #250, epoch #25, avg. train loss: 0.30838, avg. val loss: 0.38683\n",
      "Step #300, epoch #30, avg. train loss: 0.27045, avg. val loss: 0.35367\n",
      "Step #350, epoch #35, avg. train loss: 0.24080, avg. val loss: 0.32755\n",
      "Step #400, epoch #40, avg. train loss: 0.22763, avg. val loss: 0.31334\n",
      "Step #450, epoch #45, avg. train loss: 0.21902, avg. val loss: 0.29278\n",
      "Step #500, epoch #50, avg. train loss: 0.21234, avg. val loss: 0.28586\n",
      "Fold score: 0.9678372077779887\n",
      "Fold #5\n",
      "Step #50, epoch #5, avg. train loss: 1.46506, avg. val loss: 1.37566\n",
      "Step #100, epoch #10, avg. train loss: 0.68524, avg. val loss: 0.77252\n",
      "Step #150, epoch #15, avg. train loss: 0.38822, avg. val loss: 0.47817\n",
      "Step #200, epoch #20, avg. train loss: 0.27894, avg. val loss: 0.34271\n",
      "Step #250, epoch #25, avg. train loss: 0.25573, avg. val loss: 0.30434\n",
      "Step #300, epoch #30, avg. train loss: 0.23502, avg. val loss: 0.28436\n",
      "Step #350, epoch #35, avg. train loss: 0.21894, avg. val loss: 0.26923\n",
      "Step #400, epoch #40, avg. train loss: 0.19526, avg. val loss: 0.26089\n",
      "Step #450, epoch #45, avg. train loss: 0.19391, avg. val loss: 0.25363\n",
      "Step #500, epoch #50, avg. train loss: 0.19493, avg. val loss: 0.25795\n",
      "Fold score: 0.9612755239323388\n",
      "Final, Out of Sample Score: 0.9447236180904522\n"
     ]
    }
   ],
   "source": [
    "# Programming Assignment #2 by Jeff Heaton\n",
    "# T81-558: Application of Deep Learning\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "# These four functions will help you, they were covered in class.\n",
    "# Encode a text field to dummy variables\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode a text field to a single index value\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric field to Z-Scores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()        \n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "\n",
    "# Encode a numeric field to fill missing values with the median.\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert a dataframe to x/y suitable for training.\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    return df.as_matrix(result),df[target]\n",
    "    \n",
    "# Encode the toy dataset\n",
    "def encode_toy_dataset(name):\n",
    "    df = pd.read_csv(name,na_values=['NA','?'])\n",
    "    #    Generate dummy variables for the shape and metal.\n",
    "    encode_text_dummy(df,'metal')\n",
    "    encode_text_dummy(df,'shape')\n",
    "    #     Encode high, width and length as z-scores\n",
    "    encode_numeric_zscore(df,'height',mean=None,sd=None)\n",
    "    encode_numeric_zscore(df,'width',mean=None,sd=None)\n",
    "    encode_numeric_zscore(df,'length',mean=None,sd=None)\n",
    "\n",
    "    return (df)\n",
    "\n",
    "def question1():\n",
    "    print()\n",
    "    print(\"***Question 1***\")\n",
    "    \n",
    "    path = \"./data/\"\n",
    "    \n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-yutong-prog2q1.csv\")\n",
    "    df = encode_toy_dataset(filename_read) # You just have to implement encode_toy_dataset above\n",
    "    df.to_csv(filename_write,index=False)\n",
    "\n",
    "    print(\"Wrote {} lines.\".format(len(df)))\n",
    "\n",
    "def question2():\n",
    "    print()\n",
    "    print(\"***Question 2***\")\n",
    "    \n",
    "    path = \"./data/\"\n",
    "    \n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    df = encode_toy_dataset(filename_read)\n",
    "    \n",
    "    # shuffle \n",
    "    df = df.reindex(np.random.permutation(df.index)) \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,['weight'])\n",
    "    # Create a deep neural network with 3 hidden layers of 50, 25, 10\n",
    "    regressor = skflow.TensorFlowDNNRegressor(hidden_units=[50, 25, 10], steps=10000)\n",
    "     #fit nutural network\n",
    "    regressor.fit(x,y) \n",
    "    \n",
    "    # How to make many predictions\n",
    "    pred = regressor.predict(x)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "    print(\"Out of sample (RMSE): {}\".format(score))\n",
    "\n",
    "def question3():\n",
    "    print()\n",
    "    print(\"***Question 3***\")\n",
    "    # Z-Score encode these using the mean/sd from the dataset (you got ‚Üê-this in question 2)\n",
    "    testDF = pd.DataFrame([\n",
    "                {'length':1, 'width':2, 'height': 3},\n",
    "                {'length':3, 'width':2, 'height': 5},\n",
    "                {'length':4, 'width':1, 'height': 3}\n",
    "                ])\n",
    "    \n",
    "    path = \"./data/\"\n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-yutong-prog2q3.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "     #     calculate and report the mean and standard deviation for height, width and length\n",
    "    print('length: ({}, {})'.format(df['length'].mean(), df['length'].std()))\n",
    "    print('width: ({}, {})'.format(df['width'].mean(), df['width'].std()))\n",
    "    print('height: ({}, {})'.format(df['height'].mean(), df['height'].std()))\n",
    "   \n",
    "    encode_numeric_zscore(testDF,'length',mean=df['length'].mean(),sd=df['length'].std())  \n",
    "    encode_numeric_zscore(testDF,'width',mean=df['width'].mean(),sd=df['width'].std())  \n",
    "    encode_numeric_zscore(testDF,'height',mean=df['height'].mean(),sd=df['height'].std())  \n",
    "    \n",
    "\n",
    "    testDF.to_csv(filename_write,index = False)\n",
    "    print(testDF)\n",
    "    \n",
    "def question4():\n",
    "    print()\n",
    "    print(\"***Question 4***\")\n",
    "\n",
    "    path = \"./data/\"\n",
    "    filename_read = os.path.join(path,\"iris.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-yutong-prog2q4.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    \n",
    "    # create feature vector\n",
    "    encode_numeric_zscore(df,'sepal_l')\n",
    "    encode_numeric_zscore(df,'sepal_w')\n",
    "    encode_numeric_zscore(df,'petal_l')\n",
    "    encode_text_dummy(df,'species')\n",
    "    \n",
    "    # shuffle \n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace =True, drop = True)\n",
    "    \n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,'petal_w')#  predict petal-w\n",
    "    \n",
    "    # Cross validate\n",
    "    kf = KFold(len(x),n_folds =5)\n",
    "    \n",
    "    oos_y = []\n",
    "    oos_pred= []\n",
    "    fold =1 \n",
    "    for train,test in kf:\n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        fold+=1\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "        \n",
    "        # Create a deep neural network with 3 hidden layers of 10, 20, 10\n",
    "        regressor = skflow.TensorFlowDNNRegressor(hidden_units = [10,20,10],steps = 5000)\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stop = skflow.monitors.ValidationMonitor(x_test,y_test,early_stopping_rounds = 200, print_steps=50)\n",
    "        \n",
    "        # Fit/train neural network\n",
    "        regressor.fit(x_train,y_train,monitor=early_stop)\n",
    "        \n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = regressor.predict(x_test)\n",
    "        \n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)\n",
    "        \n",
    "        # Measure accuracy\n",
    "        score=np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "        print (\"Fold score (RMSE): {}\".format(score))    \n",
    "\n",
    "    # Build the oos prediction list and calculate the error.    \n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    scoreFinal=np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))  \n",
    "    print(\"Final, Out of Sample Score (RMSE): {}\".format(scoreFinal))\n",
    "    \n",
    "    # Write the cross-validated prediction\n",
    "    oos_y =pd.DataFrame(oos_y)\n",
    "    oos_pred=pd.DataFrame(oos_pred)\n",
    "    oosDF = pd.concat([df,oos_y,oos_pred],axis = 1)\n",
    "    oosDF.to_csv(filename_write, index=False)\n",
    "\n",
    "def question5():\n",
    "    print()\n",
    "    print(\"***Question 5***\")\n",
    "\n",
    "    path = \"./data/\"\n",
    "    filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-yutong-prog2q5.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    \n",
    "    # create feature vector\n",
    "    missing_median(df,'horsepower')\n",
    "    nameDF = df['name']\n",
    "    df.drop('name',1,inplace=True)\n",
    "    encode_numeric_zscore(df,'horsepower')\n",
    "    encode_numeric_zscore(df,'weight')\n",
    "    encode_numeric_zscore(df,'displacement')\n",
    "    encode_numeric_zscore(df,'mpg')\n",
    "    encode_numeric_zscore(df,'acceleration')\n",
    "    encode_numeric_zscore(df,'origin')\n",
    "    cylinders = encode_text_index(df,'cylinders')\n",
    "    num_classes= len(cylinders)\n",
    "    \n",
    "    # shuffle \n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace =True, drop = True)\n",
    "    \n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,'cylinders')#  predict cylinders\n",
    "    \n",
    "    # Cross validate\n",
    "    kf = KFold(len(x),n_folds =5)\n",
    "    \n",
    "    oos_y = []\n",
    "    oos_pred= []\n",
    "    fold =1 \n",
    "    for train,test in kf:\n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        fold+=1\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "        \n",
    "        # Create a deep neural network with 3 hidden layers of 10, 20, 10\n",
    "        classifier = skflow.TensorFlowDNNClassifier(hidden_units = [10,20,10], n_classes = num_classes, steps = 500)\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stop = skflow.monitors.ValidationMonitor(x_test, y_test, early_stopping_rounds=200, print_steps=50, n_classes = num_classes)\n",
    "        \n",
    "        # Fit/train neural network\n",
    "        classifier.fit(x_train,y_train,early_stop)\n",
    "        \n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = classifier.predict(x_test)\n",
    "        \n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)\n",
    "        \n",
    "        # Measure accuracy\n",
    "        score = np.sqrt(metrics.accuracy_score(y_test, pred))\n",
    "        print (\"Fold score: {}\".format(score))    \n",
    "\n",
    "    # Build the oos prediction list and calculate the error.    \n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    score = metrics.accuracy_score(oos_y, oos_pred)\n",
    "    print(\"Final, Out of Sample Score: {}\".format(score))\n",
    "    \n",
    "    oos_y = pd.DataFrame(oos_y)\n",
    "    oos_pred = pd.DataFrame(oos_pred)\n",
    "    \n",
    "    oos_y =pd.DataFrame(oos_y)\n",
    "    oos_pred=pd.DataFrame(oos_pred)\n",
    "    df.insert(8,'name',nameDF)  \n",
    "    df.insert(9,'ideal',oos_y)  \n",
    "    df.insert(10,'predict',oos_pred) \n",
    "\n",
    "    df.to_csv(filename_write, index = False)\n",
    "\n",
    "question1()\n",
    "question2()\n",
    "question3()\n",
    "question4()\n",
    "question5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question 5***\n",
      "Fold #1\n",
      "Step #50, epoch #5, avg. train loss: 1.51485, avg. val loss: 1.23125\n",
      "Step #100, epoch #10, avg. train loss: 0.69187, avg. val loss: 0.53933\n",
      "Step #150, epoch #15, avg. train loss: 0.44803, avg. val loss: 0.30869\n",
      "Step #200, epoch #20, avg. train loss: 0.32595, avg. val loss: 0.22045\n",
      "Step #250, epoch #25, avg. train loss: 0.28483, avg. val loss: 0.19665\n",
      "Step #300, epoch #30, avg. train loss: 0.26852, avg. val loss: 0.17732\n",
      "Step #350, epoch #35, avg. train loss: 0.24599, avg. val loss: 0.15890\n",
      "Step #400, epoch #40, avg. train loss: 0.23328, avg. val loss: 0.15374\n",
      "Step #450, epoch #45, avg. train loss: 0.21888, avg. val loss: 0.14830\n",
      "Step #500, epoch #50, avg. train loss: 0.21994, avg. val loss: 0.15145\n",
      "Fold score: 0.9810708435174292\n",
      "Fold #2\n",
      "Step #50, epoch #5, avg. train loss: 1.50325, avg. val loss: 1.35368\n",
      "Step #100, epoch #10, avg. train loss: 0.68610, avg. val loss: 0.79987\n",
      "Step #150, epoch #15, avg. train loss: 0.44881, avg. val loss: 0.60935\n",
      "Step #200, epoch #20, avg. train loss: 0.33735, avg. val loss: 0.46706\n",
      "Step #250, epoch #25, avg. train loss: 0.27719, avg. val loss: 0.38541\n",
      "Step #300, epoch #30, avg. train loss: 0.24578, avg. val loss: 0.33329\n",
      "Step #350, epoch #35, avg. train loss: 0.23143, avg. val loss: 0.30299\n",
      "Step #400, epoch #40, avg. train loss: 0.20649, avg. val loss: 0.27676\n",
      "Step #450, epoch #45, avg. train loss: 0.18573, avg. val loss: 0.25823\n",
      "Step #500, epoch #50, avg. train loss: 0.19556, avg. val loss: 0.26374\n",
      "Fold score: 0.9746794344808963\n",
      "Fold #3\n",
      "Step #50, epoch #5, avg. train loss: 1.48688, avg. val loss: 1.32485\n",
      "Step #100, epoch #10, avg. train loss: 0.77892, avg. val loss: 0.81879\n",
      "Step #150, epoch #15, avg. train loss: 0.60576, avg. val loss: 0.66166\n",
      "Step #200, epoch #20, avg. train loss: 0.52940, avg. val loss: 0.59634\n",
      "Step #250, epoch #25, avg. train loss: 0.48060, avg. val loss: 0.55534\n",
      "Step #300, epoch #30, avg. train loss: 0.44777, avg. val loss: 0.51979\n",
      "Step #350, epoch #35, avg. train loss: 0.42587, avg. val loss: 0.49135\n",
      "Step #400, epoch #40, avg. train loss: 0.40386, avg. val loss: 0.46887\n",
      "Step #450, epoch #45, avg. train loss: 0.38771, avg. val loss: 0.44600\n",
      "Step #500, epoch #50, avg. train loss: 0.37028, avg. val loss: 0.42531\n",
      "Fold score: 0.9746794344808963\n",
      "Fold #4\n",
      "Step #50, epoch #5, avg. train loss: 1.45293, avg. val loss: 1.35825\n",
      "Step #100, epoch #10, avg. train loss: 0.74098, avg. val loss: 0.72190\n",
      "Step #150, epoch #15, avg. train loss: 0.48421, avg. val loss: 0.49895\n",
      "Step #200, epoch #20, avg. train loss: 0.37166, avg. val loss: 0.42331\n",
      "Step #250, epoch #25, avg. train loss: 0.30838, avg. val loss: 0.38683\n",
      "Step #300, epoch #30, avg. train loss: 0.27045, avg. val loss: 0.35367\n",
      "Step #350, epoch #35, avg. train loss: 0.24080, avg. val loss: 0.32755\n",
      "Step #400, epoch #40, avg. train loss: 0.22763, avg. val loss: 0.31334\n",
      "Step #450, epoch #45, avg. train loss: 0.21902, avg. val loss: 0.29278\n",
      "Step #500, epoch #50, avg. train loss: 0.21234, avg. val loss: 0.28586\n",
      "Fold score: 0.9678372077779887\n",
      "Fold #5\n",
      "Step #50, epoch #5, avg. train loss: 1.46506, avg. val loss: 1.37566\n",
      "Step #100, epoch #10, avg. train loss: 0.68524, avg. val loss: 0.77252\n",
      "Step #150, epoch #15, avg. train loss: 0.38822, avg. val loss: 0.47817\n",
      "Step #200, epoch #20, avg. train loss: 0.27894, avg. val loss: 0.34271\n",
      "Step #250, epoch #25, avg. train loss: 0.25573, avg. val loss: 0.30434\n",
      "Step #300, epoch #30, avg. train loss: 0.23502, avg. val loss: 0.28436\n",
      "Step #350, epoch #35, avg. train loss: 0.21894, avg. val loss: 0.26923\n",
      "Step #400, epoch #40, avg. train loss: 0.19526, avg. val loss: 0.26089\n",
      "Step #450, epoch #45, avg. train loss: 0.19391, avg. val loss: 0.25363\n",
      "Step #500, epoch #50, avg. train loss: 0.19493, avg. val loss: 0.25795\n",
      "Fold score: 0.9612755239323388\n",
      "Final, Out of Sample Score: 0.9447236180904522\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
